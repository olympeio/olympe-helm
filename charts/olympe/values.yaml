# -- Docker repository for the resource image
appRepository: olympeio/olympe-composer

neo4j:
  enabled: true
  image:
    customImage: olympeio/olympe-database:v2.4.5
  fullnameOverride: neo4j
  neo4j:
    password: olympe
  services:
    neo4j:
      spec:
        type: ClusterIP
  volumes:
    data:
      mode: defaultStorageClass
      defaultStorageClass:
        requests:
          storage: 20Gi

rabbitmq:
  enabled: true
  fullnameOverride: rabbitmq
  extraPlugins:
    - rabbitmq_web_mqtt
    - rabbitmq_auth_mechanism_ssl
    - rabbitmq_auth_backend_cache
    - rabbitmq_auth_backend_http
  auth:
    username: guest
    password: guest
  extraConfiguration: |-
    default_vhost = orchestrator
    default_permissions.configure = .*
    default_permissions.read = .*
    default_permissions.write = .*
    auth_backends.1         = internal
    auth_backends.2         = http
    auth_http.http_method   = post
    auth_http.user_path     = http://orchestrator:8080/auth/user
    auth_http.vhost_path    = http://orchestrator:8080/auth/vhost
    auth_http.resource_path = http://orchestrator:8080/auth/resource
    auth_http.topic_path    = http://orchestrator:8080/auth/topic
  service:
    extraPorts:
      - name: mqtt
        port: 15675
        targetPort: 15675

# -- Please check the license agreement: https://
acceptLicenseAgreement: "no"

image:
  # -- Image pull policy
  pullPolicy: Always

# -- partially override realease name
nameOverride: ""

# -- fully override release name
fullnameOverride: ""

# -- Define if a project is enabled or not. If not, replicas will be set to 0 but data will be kept
enabled: true

frontend:
  # -- Number of frontend replicas
  replicas: 1
  # -- frontend image
  image:
    repository: olympeio
    name: olympe-frontend
  # -- frontend environment variables
  env: {}
  # -- frontend port
  port: 80
  # -- additional frontend configuration
  additionalConfig: ""
  # -- frontend oConfig content
  oConfig: ""
  rabbitmq:
    host: rabbitmq
    mqttPort: 15675
  resources:
    requests:
      # -- frontend memory request. See [Kubernetes documentation](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers)
      # memory: "100Mi"
      # -- frontend CPU request. See [Kubernetes documentation](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers)
      # cpu: "50m"
    limits:
      # -- frontend memory limit. See [Kubernetes documentation](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers)
      # memory: "150Mi"
      # -- frontend CPU limit. See [Kubernetes documentation](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers)
      # cpu: "100m"
  # -- defines privilege and access control settings for the frontend on Pod level.
  podSecurityContext:
    runAsUser: 101
  # -- defines privilege and access control settings for the frontend on Container level.
  containerSecurityContext:
    allowPrivilegeEscalation: false
  
  # -- setup nodeSelector for the frontend. Please see [Kubernetes documentation](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/)
  nodeSelector: {}
  # -- setup tolerations for the frontend. Please see [Kubernetes documentation](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
  tolerations: []
  # -- setup affinity for the frontend. Please see [Kubernetes documentation](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
  affinity: {}
  # -- setup dataVolume for the frontend
  dataVolume:
    storageClassName: standard

olympeToolkit:
  # -- available values are:
  #     - help
  #     - snapshot
  #     - snapshotUsers
  #     - snapshotBusinessData
  #     - restoreUsers
  #     - restoreBusinessData
  #     - reset
  #     - checkDB
  #     - startGC
  #     - statsDB
  #     - maintenance
  #     - updateUser
  #     
  cronJobs:
    garbageCollector:
      name: garbage-collector
      command: startGC
      spec:
        schedule: 5 1 * * 0
        resources:
          requests:
            memory: "100Mi"
            cpu: "100m"
          limits:
            memory: "100Mi"
            cpu: "100m"

  # -- Olympe Toolkit image
  image:
    repository: olympeio
    name: olympe-toolkit
    tag: latest
  # -- defines privilege and access control settings for the Olympe Tools on Pod level.
  podSecurityContext:
    runAsUser: 0

orchestrator:
  # -- Number of orchestrator replicas
  replicas: 1
  # -- Orchestrator image
  image:
    repository: olympeio
    name: olympe-orchestrator
  # -- Orchestrator cluster type. Can be "none", "infinispan" or "hazelcast"
  clusterType: none
  # -- Orchestrator HA setup
  haEnabled: false
  # -- Orchestrator environment variables (in statefulset)
  env:
  # -- Orchestrator environment variables (in separated configMap)
  configMapEnv:
    PERMISSION_CHECK_ENABLED: "false"
    WAIT_FOR_NEO4J: "120"
    RABBITMQ_CLIENT_PREFETCH_SIZE: 200
    JAVA_PROCESS_XMX: 1g
    ALLOWED_WS_ORIGINS: "|.*"
    ACTIVITY_TIMEOUT: "70000000"
  existingSecret: ""
  # -- secretRef value for orchestrator
  secretRef:
  neo4j:
    # -- protocol
    protocol: bolt
    # -- hostname of Neo4j (default to project cluster)
    hostname:
    # -- shared neo4j root password
    rootPassword: password1
    # -- database name of the project (defaults to project name without hyphen)
    dbName:
    # -- database username of the project (defaults to project name without hyphen)
    dbUsername: neo4j
    # -- database user password of the project (defaults to a 12 characters randomly generated string)
    dbUserPassword: olympe
    # -- Toggle resetdb execution at project creation only
    resetDB: true
    # -- Toggle createdb execution at project creation only
    createDB: true
  rabbitmq:
    # -- rabbitMQ host
    host: rabbitmq
    # -- rabbitMQ port
    port: 5672
    # -- rabbitMQ username
    username: guest
    # -- rabbitMQ orchestrator username
    orchestratorUsername: guest
    # -- rabbitMQ password
    password: guest
    # -- rabbitMQ orchestrator password
    orchestratorPassword: guest
  resources:
    requests:
      # -- Orchestrator memory request. See [Kubernetes documentation](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers)
      # memory: "600Mi"
      # -- Orchestrator CPU request. See [Kubernetes documentation](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers)
      # cpu: "100m"
    limits:
      # -- Orchestrator memory limit. See [Kubernetes documentation](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers)
      # memory: "800Mi"
      # -- Orchestrator CPU limit. See [Kubernetes documentation](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers)
      # cpu: "300m"
  # -- setup nodeSelector for the orchestrator. Please see [Kubernetes documentation](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/)
  nodeSelector: {}
  # -- setup tolerations for the orchestrator. Please see [Kubernetes documentation](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
  tolerations: []
  # -- setup affinity for the orchestrator. Please see [Kubernetes documentation](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
  affinity: {}
  # -- setup dataVolume for the frontend
  dataVolume:
    storageClassName: standard
    fileService: {}
    backupData: {}
  # -- defines privilege and access control settings for the Orchestrator on Pod level.
  podSecurityContext:
    runAsUser: 1000
  # -- defines privilege and access control settings for the Orchestrator on Container level.
  containerSecurityContext:
    allowPrivilegeEscalation: false
  # -- enable Prometheus metrics
  prometheus:
    enabled: false
  # Orchestrator liveness probe
  livenessProbe:
    httpGet:
      path: /readiness
      port: 8082
    failureThreshold: 10
  # Orchestrator startup probe
  startupProbe:
    httpGet:
      path: /readiness
      port: 8082
    failureThreshold: 10

# -- Service Apps configuration. Please see the example folders for more details
serviceApps: {}
#  node
#    replicas: 1
#    ports:
#      - 80

# -- Default Service Apps image
serviceAppsImage: node:14.21.3-slim
serviceAppsDefaultPort: 2015

serviceAccount:
  # -- Specifies whether a service account should be created
  create: true
  # -- Annotations to add to the service account
  annotations: {}
  # -- The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name:

# -- Snapshooters configuration, You can have multiple of them, each with the following values:<br />
# - name: string, mandatory - Name of the snapshooter <br />
#    schedule: string, mandatory - schedule (cron format) <br />
#    config: string, json configuration. Please read documentation for examples (can't be used with secretName key below) <br />
#    secretName: string, name of the secret containing the configuration (can't be used with config key above) <br />
#    resources <br />
#      requests: <br />
#        memory: string, default "200Mi" <br />
#        cpu: string, default "100m" <br />
#      limits: <br />
#        memory: string, default "1000Mi" <br />
#        cpu: string, default "200m" <br />
snapshooters: []

# -- Frontend service configuration
service:
  type: ClusterIP
  port: 80

# -- Ingress configuration
ingress:
  enabled: false
  annotations:
    # change this in case you are not using nginx as ingress-controller
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "36000"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "36000"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "36000"

  hosts:
    - olympe.local
  extraPaths: []
  tls:
    - secretName:
      hosts: []